{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8b10f2c0116060b917de9f4c6229bc18f72358dd"
   },
   "source": [
    "# Dimensionality reduction using Keras Auto Encoder\n",
    "\n",
    "* Prepare Data\n",
    "* Design Auto Encoder\n",
    "* Train Auto Encoder\n",
    "* Use Encoder level from Auto Encoder\n",
    "* Use Encoder to obtain reduced dimensionality data for train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'sample_submission.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from numpy.random import seed\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plote\n",
    "\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "39b71a439c6eb7b9f139805ec07e572f3dce0b03"
   },
   "source": [
    "## Read train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "_uuid": "ff255be01ca0660a6fe91fe62046712d60deda7b"
   },
   "outputs": [],
   "source": [
    "train2 = train.copy()\n",
    "train3 = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d0c7ce7f80d13a05ac8668306118476376f541e1"
   },
   "source": [
    "## Dropping Target and ID's from train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "_uuid": "ed1dd2d2420ed09ecbd22681d638fcd8b594a7e6"
   },
   "outputs": [],
   "source": [
    "#target = train['target']\n",
    "#train_id = train['ID']\n",
    "#test_id = test['ID']\n",
    "\n",
    "#train.drop(['target'], axis=1, inplace=True)\n",
    "#train.drop(['ID'], axis=1, inplace=True)\n",
    "#test.drop(['ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "_uuid": "af87534bb5a7cb9f2785de8522ea6fdb9e605aa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape (3567, 4991)\n",
      "Test data shape (892, 4991)\n"
     ]
    }
   ],
   "source": [
    "print('Train data shape', X_train.shape)\n",
    "print('Test data shape', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2f9e31651ff65cb57d2c1c261b41f03d216508c"
   },
   "source": [
    "### Scaling Train and Test data for Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "_uuid": "04df668adc11e9bb8bb6c232b80ca5da6aeb8d4f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>dc5a8f1d8</th>\n",
       "      <th>11d86fa6a</th>\n",
       "      <th>77c9823f2</th>\n",
       "      <th>8d6c2a0b2</th>\n",
       "      <th>4681de4fd</th>\n",
       "      <th>adf119b9a</th>\n",
       "      <th>cff75dd09</th>\n",
       "      <th>96f83a237</th>\n",
       "      <th>b8a716ebf</th>\n",
       "      <th>6c7a4567c</th>\n",
       "      <th>4fcfd2b4d</th>\n",
       "      <th>f3b9c0b95</th>\n",
       "      <th>71cebf11c</th>\n",
       "      <th>d966ac62c</th>\n",
       "      <th>68b647452</th>\n",
       "      <th>c88d108c9</th>\n",
       "      <th>ff7b471cd</th>\n",
       "      <th>d5308d8bc</th>\n",
       "      <th>0d866c3d7</th>\n",
       "      <th>bc3f77679</th>\n",
       "      <th>bd8f989f1</th>\n",
       "      <th>0eff5bf95</th>\n",
       "      <th>22ed6dba3</th>\n",
       "      <th>92b13ebba</th>\n",
       "      <th>c330f1a67</th>\n",
       "      <th>233c7c17c</th>\n",
       "      <th>2cb4d123e</th>\n",
       "      <th>eeac16933</th>\n",
       "      <th>87ffda550</th>\n",
       "      <th>822e49b95</th>\n",
       "      <th>...</th>\n",
       "      <th>969caa87a</th>\n",
       "      <th>00302fe51</th>\n",
       "      <th>1189ee335</th>\n",
       "      <th>ca04a07ca</th>\n",
       "      <th>f6f15ffa5</th>\n",
       "      <th>841704460</th>\n",
       "      <th>ea5ed6ff7</th>\n",
       "      <th>b1bb8eac3</th>\n",
       "      <th>8132d18b8</th>\n",
       "      <th>c24ea6548</th>\n",
       "      <th>cdfc2b069</th>\n",
       "      <th>2a879b4f7</th>\n",
       "      <th>6b119d8ce</th>\n",
       "      <th>98dea9e42</th>\n",
       "      <th>9f2471031</th>\n",
       "      <th>88458cb21</th>\n",
       "      <th>f40da20f4</th>\n",
       "      <th>7ad6b38bd</th>\n",
       "      <th>c901e7df1</th>\n",
       "      <th>8f55955dc</th>\n",
       "      <th>85dcc913d</th>\n",
       "      <th>5ca0b9b0c</th>\n",
       "      <th>eab8abf7a</th>\n",
       "      <th>8d8bffbae</th>\n",
       "      <th>2a1f6c7f9</th>\n",
       "      <th>9437d8b64</th>\n",
       "      <th>5831f4c76</th>\n",
       "      <th>2e84e09c5</th>\n",
       "      <th>d45fd5508</th>\n",
       "      <th>a165f5761</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.893303</td>\n",
       "      <td>-0.037646</td>\n",
       "      <td>-0.021639</td>\n",
       "      <td>-0.04689</td>\n",
       "      <td>-0.019205</td>\n",
       "      <td>-0.017437</td>\n",
       "      <td>-0.053221</td>\n",
       "      <td>-0.022451</td>\n",
       "      <td>-0.024846</td>\n",
       "      <td>-0.267393</td>\n",
       "      <td>-0.097765</td>\n",
       "      <td>-0.081369</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.028876</td>\n",
       "      <td>-0.145479</td>\n",
       "      <td>-0.088577</td>\n",
       "      <td>-0.056368</td>\n",
       "      <td>-0.032868</td>\n",
       "      <td>-0.122579</td>\n",
       "      <td>-0.050539</td>\n",
       "      <td>-0.06967</td>\n",
       "      <td>-0.070391</td>\n",
       "      <td>-0.028072</td>\n",
       "      <td>-0.063838</td>\n",
       "      <td>-0.097167</td>\n",
       "      <td>-0.0418</td>\n",
       "      <td>-0.02571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.106546</td>\n",
       "      <td>-0.024702</td>\n",
       "      <td>-0.195458</td>\n",
       "      <td>-0.026732</td>\n",
       "      <td>-0.190989</td>\n",
       "      <td>-0.131103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.109261</td>\n",
       "      <td>-0.09053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006855</td>\n",
       "      <td>-0.147928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016098</td>\n",
       "      <td>-0.048588</td>\n",
       "      <td>0.06917</td>\n",
       "      <td>-0.078241</td>\n",
       "      <td>-0.01947</td>\n",
       "      <td>-0.068648</td>\n",
       "      <td>-0.154269</td>\n",
       "      <td>-0.131145</td>\n",
       "      <td>1.897559</td>\n",
       "      <td>-0.127742</td>\n",
       "      <td>0.098504</td>\n",
       "      <td>-0.109831</td>\n",
       "      <td>-0.136631</td>\n",
       "      <td>-0.016835</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.035221</td>\n",
       "      <td>-0.025053</td>\n",
       "      <td>-0.086555</td>\n",
       "      <td>0.310269</td>\n",
       "      <td>-0.036796</td>\n",
       "      <td>-0.062993</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.108148</td>\n",
       "      <td>-0.117917</td>\n",
       "      <td>-0.057864</td>\n",
       "      <td>-0.103842</td>\n",
       "      <td>-0.181415</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.029019</td>\n",
       "      <td>-0.096534</td>\n",
       "      <td>-0.114959</td>\n",
       "      <td>-0.100403</td>\n",
       "      <td>-0.178522</td>\n",
       "      <td>-0.114247</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.025715</td>\n",
       "      <td>-0.022134</td>\n",
       "      <td>-0.072342</td>\n",
       "      <td>-0.056363</td>\n",
       "      <td>-0.125852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.649177</td>\n",
       "      <td>-0.037646</td>\n",
       "      <td>-0.021639</td>\n",
       "      <td>-0.04689</td>\n",
       "      <td>-0.019205</td>\n",
       "      <td>-0.017437</td>\n",
       "      <td>-0.053221</td>\n",
       "      <td>-0.022451</td>\n",
       "      <td>-0.024846</td>\n",
       "      <td>-0.038443</td>\n",
       "      <td>-0.097765</td>\n",
       "      <td>-0.081369</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.028876</td>\n",
       "      <td>-0.145479</td>\n",
       "      <td>-0.088577</td>\n",
       "      <td>-0.056368</td>\n",
       "      <td>-0.032868</td>\n",
       "      <td>-0.122579</td>\n",
       "      <td>-0.050539</td>\n",
       "      <td>-0.06967</td>\n",
       "      <td>-0.070391</td>\n",
       "      <td>-0.028072</td>\n",
       "      <td>-0.063838</td>\n",
       "      <td>-0.097167</td>\n",
       "      <td>-0.0418</td>\n",
       "      <td>-0.02571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.106546</td>\n",
       "      <td>-0.024702</td>\n",
       "      <td>-0.195458</td>\n",
       "      <td>-0.026732</td>\n",
       "      <td>-0.190989</td>\n",
       "      <td>-0.131103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.109261</td>\n",
       "      <td>-0.09053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.169767</td>\n",
       "      <td>-0.147928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016098</td>\n",
       "      <td>-0.048588</td>\n",
       "      <td>-0.10653</td>\n",
       "      <td>-0.078241</td>\n",
       "      <td>-0.01947</td>\n",
       "      <td>-0.068648</td>\n",
       "      <td>-0.154269</td>\n",
       "      <td>-0.131145</td>\n",
       "      <td>-0.090717</td>\n",
       "      <td>-0.127742</td>\n",
       "      <td>-0.181402</td>\n",
       "      <td>-0.109831</td>\n",
       "      <td>-0.136631</td>\n",
       "      <td>-0.016835</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.035221</td>\n",
       "      <td>-0.025053</td>\n",
       "      <td>-0.086555</td>\n",
       "      <td>-0.100021</td>\n",
       "      <td>-0.036796</td>\n",
       "      <td>-0.062993</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.108148</td>\n",
       "      <td>-0.117917</td>\n",
       "      <td>-0.057864</td>\n",
       "      <td>-0.103842</td>\n",
       "      <td>-0.181415</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.029019</td>\n",
       "      <td>-0.096534</td>\n",
       "      <td>-0.114959</td>\n",
       "      <td>-0.100403</td>\n",
       "      <td>-0.178522</td>\n",
       "      <td>-0.114247</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.025715</td>\n",
       "      <td>-0.022134</td>\n",
       "      <td>-0.072342</td>\n",
       "      <td>-0.056363</td>\n",
       "      <td>-0.125852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.492516</td>\n",
       "      <td>-0.037646</td>\n",
       "      <td>-0.021639</td>\n",
       "      <td>-0.04689</td>\n",
       "      <td>-0.019205</td>\n",
       "      <td>-0.017437</td>\n",
       "      <td>-0.053221</td>\n",
       "      <td>-0.022451</td>\n",
       "      <td>-0.024846</td>\n",
       "      <td>-0.267393</td>\n",
       "      <td>-0.097765</td>\n",
       "      <td>-0.081369</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.028876</td>\n",
       "      <td>-0.145479</td>\n",
       "      <td>-0.088577</td>\n",
       "      <td>-0.056368</td>\n",
       "      <td>-0.032868</td>\n",
       "      <td>-0.122579</td>\n",
       "      <td>-0.050539</td>\n",
       "      <td>-0.06967</td>\n",
       "      <td>-0.070391</td>\n",
       "      <td>-0.028072</td>\n",
       "      <td>-0.063838</td>\n",
       "      <td>-0.097167</td>\n",
       "      <td>-0.0418</td>\n",
       "      <td>-0.02571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.106546</td>\n",
       "      <td>-0.024702</td>\n",
       "      <td>-0.195458</td>\n",
       "      <td>-0.026732</td>\n",
       "      <td>-0.190989</td>\n",
       "      <td>-0.131103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.109261</td>\n",
       "      <td>-0.09053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.169767</td>\n",
       "      <td>-0.147928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016098</td>\n",
       "      <td>-0.048588</td>\n",
       "      <td>-0.10653</td>\n",
       "      <td>-0.078241</td>\n",
       "      <td>-0.01947</td>\n",
       "      <td>-0.068648</td>\n",
       "      <td>-0.154269</td>\n",
       "      <td>-0.131145</td>\n",
       "      <td>-0.090717</td>\n",
       "      <td>-0.127742</td>\n",
       "      <td>-0.181402</td>\n",
       "      <td>-0.109831</td>\n",
       "      <td>-0.136631</td>\n",
       "      <td>-0.016835</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.035221</td>\n",
       "      <td>-0.025053</td>\n",
       "      <td>-0.086555</td>\n",
       "      <td>-0.100021</td>\n",
       "      <td>-0.036796</td>\n",
       "      <td>-0.062993</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.108148</td>\n",
       "      <td>-0.117917</td>\n",
       "      <td>-0.057864</td>\n",
       "      <td>-0.103842</td>\n",
       "      <td>-0.181415</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.029019</td>\n",
       "      <td>-0.096534</td>\n",
       "      <td>-0.114959</td>\n",
       "      <td>-0.100403</td>\n",
       "      <td>-0.178522</td>\n",
       "      <td>-0.114247</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.025715</td>\n",
       "      <td>-0.022134</td>\n",
       "      <td>-0.072342</td>\n",
       "      <td>-0.056363</td>\n",
       "      <td>-0.125852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.479137</td>\n",
       "      <td>-0.037646</td>\n",
       "      <td>-0.021639</td>\n",
       "      <td>-0.04689</td>\n",
       "      <td>-0.019205</td>\n",
       "      <td>-0.017437</td>\n",
       "      <td>-0.053221</td>\n",
       "      <td>-0.022451</td>\n",
       "      <td>-0.024846</td>\n",
       "      <td>-0.267393</td>\n",
       "      <td>-0.097765</td>\n",
       "      <td>-0.081369</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.028876</td>\n",
       "      <td>-0.145479</td>\n",
       "      <td>-0.088577</td>\n",
       "      <td>-0.056368</td>\n",
       "      <td>-0.032868</td>\n",
       "      <td>-0.122579</td>\n",
       "      <td>-0.050539</td>\n",
       "      <td>-0.06967</td>\n",
       "      <td>-0.070391</td>\n",
       "      <td>-0.028072</td>\n",
       "      <td>-0.063838</td>\n",
       "      <td>-0.097167</td>\n",
       "      <td>-0.0418</td>\n",
       "      <td>-0.02571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.106546</td>\n",
       "      <td>-0.024702</td>\n",
       "      <td>-0.195458</td>\n",
       "      <td>-0.026732</td>\n",
       "      <td>-0.190989</td>\n",
       "      <td>-0.131103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.109261</td>\n",
       "      <td>-0.09053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.169767</td>\n",
       "      <td>-0.147928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016098</td>\n",
       "      <td>-0.048588</td>\n",
       "      <td>-0.10653</td>\n",
       "      <td>-0.078241</td>\n",
       "      <td>-0.01947</td>\n",
       "      <td>-0.068648</td>\n",
       "      <td>-0.154269</td>\n",
       "      <td>-0.131145</td>\n",
       "      <td>-0.090717</td>\n",
       "      <td>-0.127742</td>\n",
       "      <td>-0.181402</td>\n",
       "      <td>-0.109831</td>\n",
       "      <td>-0.136631</td>\n",
       "      <td>-0.016835</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.035221</td>\n",
       "      <td>-0.025053</td>\n",
       "      <td>-0.086555</td>\n",
       "      <td>-0.100021</td>\n",
       "      <td>-0.036796</td>\n",
       "      <td>-0.062993</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.108148</td>\n",
       "      <td>-0.117917</td>\n",
       "      <td>-0.057864</td>\n",
       "      <td>-0.103842</td>\n",
       "      <td>-0.181415</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.029019</td>\n",
       "      <td>-0.096534</td>\n",
       "      <td>-0.114959</td>\n",
       "      <td>-0.100403</td>\n",
       "      <td>-0.178522</td>\n",
       "      <td>-0.114247</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.025715</td>\n",
       "      <td>-0.022134</td>\n",
       "      <td>-0.072342</td>\n",
       "      <td>-0.056363</td>\n",
       "      <td>-0.125852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.026926</td>\n",
       "      <td>-0.037646</td>\n",
       "      <td>-0.021639</td>\n",
       "      <td>-0.04689</td>\n",
       "      <td>-0.019205</td>\n",
       "      <td>-0.017437</td>\n",
       "      <td>-0.053221</td>\n",
       "      <td>-0.022451</td>\n",
       "      <td>-0.024846</td>\n",
       "      <td>-0.059257</td>\n",
       "      <td>-0.097765</td>\n",
       "      <td>-0.081369</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.028876</td>\n",
       "      <td>-0.145479</td>\n",
       "      <td>-0.088577</td>\n",
       "      <td>-0.056368</td>\n",
       "      <td>-0.032868</td>\n",
       "      <td>-0.122579</td>\n",
       "      <td>-0.050539</td>\n",
       "      <td>-0.06967</td>\n",
       "      <td>-0.070391</td>\n",
       "      <td>-0.028072</td>\n",
       "      <td>-0.063838</td>\n",
       "      <td>-0.097167</td>\n",
       "      <td>-0.0418</td>\n",
       "      <td>-0.02571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.106546</td>\n",
       "      <td>-0.024702</td>\n",
       "      <td>-0.195458</td>\n",
       "      <td>-0.026732</td>\n",
       "      <td>-0.190989</td>\n",
       "      <td>-0.131103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.109261</td>\n",
       "      <td>-0.09053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.169767</td>\n",
       "      <td>-0.147928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016098</td>\n",
       "      <td>-0.048588</td>\n",
       "      <td>-0.10653</td>\n",
       "      <td>-0.078241</td>\n",
       "      <td>-0.01947</td>\n",
       "      <td>-0.068648</td>\n",
       "      <td>-0.154269</td>\n",
       "      <td>-0.131145</td>\n",
       "      <td>-0.090717</td>\n",
       "      <td>-0.127742</td>\n",
       "      <td>-0.181402</td>\n",
       "      <td>-0.109831</td>\n",
       "      <td>-0.136631</td>\n",
       "      <td>-0.016835</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.035221</td>\n",
       "      <td>-0.025053</td>\n",
       "      <td>-0.086555</td>\n",
       "      <td>-0.100021</td>\n",
       "      <td>-0.036796</td>\n",
       "      <td>-0.062993</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.108148</td>\n",
       "      <td>-0.117917</td>\n",
       "      <td>-0.057864</td>\n",
       "      <td>-0.103842</td>\n",
       "      <td>-0.181415</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.029019</td>\n",
       "      <td>-0.096534</td>\n",
       "      <td>-0.114959</td>\n",
       "      <td>-0.100403</td>\n",
       "      <td>-0.178522</td>\n",
       "      <td>-0.114247</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-0.025715</td>\n",
       "      <td>-0.022134</td>\n",
       "      <td>-0.072342</td>\n",
       "      <td>-0.056363</td>\n",
       "      <td>-0.125852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  48df886f9  0deb4b6a8    ...      fb36b89d9  7e293fbaf  9fc776466\n",
       "0  3.893303  -0.037646  -0.021639    ...      -0.072342  -0.056363  -0.125852\n",
       "1 -0.649177  -0.037646  -0.021639    ...      -0.072342  -0.056363  -0.125852\n",
       "2  0.492516  -0.037646  -0.021639    ...      -0.072342  -0.056363  -0.125852\n",
       "3 -0.479137  -0.037646  -0.021639    ...      -0.072342  -0.056363  -0.125852\n",
       "4  1.026926  -0.037646  -0.021639    ...      -0.072342  -0.056363  -0.125852\n",
       "\n",
       "[5 rows x 4992 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_scaled = minmax_scale(train, axis = 0)\n",
    "#test_scaled = min3max_scale(test, axis = 0)\n",
    "scale_list = train3.columns[1:]\n",
    "sc = train3[scale_list]\n",
    "scaler = StandardScaler()\n",
    "sc = scaler.fit_transform(sc)\n",
    "train3[scale_list] = sc\n",
    "train3[scale_list].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b32832f691025169f8bb7f5e1915d4fa803a17ef"
   },
   "source": [
    "\n",
    "\n",
    "## Design Auto Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "75c72115094ded153c6a88ca9f9217e01f29fff4"
   },
   "source": [
    "\n",
    "\n",
    "Auto Encoders are is a type of artificial neural network used to learn efficient data patterns in an unsupervised manner. An Auto Encoder ideally consists of an encoder and decoder. \n",
    "\n",
    "The Neural Network is designed compress data using the Encoding level. The Decoder will try to uncompress the data to the original dimension.\n",
    "\n",
    "To achieve this, the Neural net is trained using the Training data as the training features as well as target.\n",
    "\n",
    "```\n",
    "# Training a Typical Neural Net\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Training a Auto Encoder\n",
    "model.fit(X_train, X_train)\n",
    "```\n",
    "\n",
    "These are typically used for dimensionality reduction use cases where there are more number of features.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "_uuid": "e9495a24eb7cee97996133a29981b1c8c5a6a639"
   },
   "outputs": [],
   "source": [
    "# define the number of features\n",
    "ncol = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "_uuid": "b2e90e3f25028664c7f693e8ca287bb9a67fb330"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4991"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d81ca355c80d85af2e877afa6458c59eec2cfca"
   },
   "source": [
    "### Split train data into train and validation 80:20 in ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "_uuid": "9f4ab18558e8f0625a34d0131be2ee9e8827f82b"
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, Y_train, Y_test = train_test_split(train_scaled, target, train_size = 0.9, random_state = seed(2017))\n",
    "\n",
    "X3 = train3.drop(['target','ID'], axis=1)\n",
    "Y3 = train3['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y ,test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "_uuid": "931d8651580f7059a5f9ba0aee15340168dba85a"
   },
   "outputs": [],
   "source": [
    "### Define the encoder dimension\n",
    "encoding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "_uuid": "4febb56ae76546b78ea0eb1920fe9c6fe606248c"
   },
   "outputs": [],
   "source": [
    "input_dim = Input(shape = (ncol, ))\n",
    "\n",
    "# Encoder Layers\n",
    "encoded1 = Dense(3000, activation = 'relu')(input_dim)\n",
    "encoded2 = Dense(2750, activation = 'relu')(encoded1)\n",
    "encoded3 = Dense(2500, activation = 'relu')(encoded2)\n",
    "encoded4 = Dense(2250, activation = 'relu')(encoded3)\n",
    "encoded5 = Dense(2000, activation = 'relu')(encoded4)\n",
    "encoded6 = Dense(1750, activation = 'relu')(encoded5)\n",
    "encoded7 = Dense(1500, activation = 'relu')(encoded6)\n",
    "encoded8 = Dense(1250, activation = 'relu')(encoded7)\n",
    "encoded9 = Dense(1000, activation = 'relu')(encoded8)\n",
    "encoded10 = Dense(750, activation = 'relu')(encoded9)\n",
    "encoded11 = Dense(500, activation = 'relu')(encoded10)\n",
    "encoded12 = Dense(250, activation = 'relu')(encoded11)\n",
    "encoded13 = Dense(encoding_dim, activation = 'relu')(encoded12)\n",
    "\n",
    "# Decoder Layers\n",
    "decoded1 = Dense(250, activation = 'relu')(encoded13)\n",
    "decoded2 = Dense(500, activation = 'relu')(decoded1)\n",
    "decoded3 = Dense(750, activation = 'relu')(decoded2)\n",
    "decoded4 = Dense(1000, activation = 'relu')(decoded3)\n",
    "decoded5 = Dense(1250, activation = 'relu')(decoded4)\n",
    "decoded6 = Dense(1500, activation = 'relu')(decoded5)\n",
    "decoded7 = Dense(1750, activation = 'relu')(decoded6)\n",
    "decoded8 = Dense(2000, activation = 'relu')(decoded7)\n",
    "decoded9 = Dense(2250, activation = 'relu')(decoded8)\n",
    "decoded10 = Dense(2500, activation = 'relu')(decoded9)\n",
    "decoded11 = Dense(2750, activation = 'relu')(decoded10)\n",
    "decoded12 = Dense(3000, activation = 'relu')(decoded11)\n",
    "decoded13 = Dense(ncol, activation = 'sigmoid')(decoded12)\n",
    "\n",
    "# Combine Encoder and Deocder layers\n",
    "autoencoder = Model(inputs = input_dim, outputs = decoded13)\n",
    "\n",
    "# Compile the Model\n",
    "autoencoder.compile(optimizer = 'adadelta', loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "_uuid": "9794eae1505676184670ed4a903ff3f0de8d82ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 4991)              0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 3000)              14976000  \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 2750)              8252750   \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 2500)              6877500   \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 2250)              5627250   \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 2000)              4502000   \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 1750)              3501750   \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 1500)              2626500   \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 1250)              1876250   \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 1000)              1251000   \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 750)               750750    \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 500)               375500    \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 200)               50200     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 500)               125500    \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 750)               375750    \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 1000)              751000    \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1250)              1251250   \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 1500)              1876500   \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 1750)              2626750   \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 2000)              3502000   \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 2250)              4502250   \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 2500)              5627500   \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 2750)              6877750   \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 3000)              8253000   \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 4991)              14977991  \n",
      "=================================================================\n",
      "Total params: 101,590,191\n",
      "Trainable params: 101,590,191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "32e795da4f94a666b3c33303d05db0cf615805e0"
   },
   "source": [
    "### Train Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "_uuid": "5f6f4b5d56d60b543a74678e68c75c8b59b00a90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3567 samples, validate on 892 samples\n",
      "Epoch 1/10\n",
      "3567/3567 [==============================] - 30s 8ms/step - loss: 0.6881 - val_loss: 0.6795\n",
      "Epoch 2/10\n",
      "3567/3567 [==============================] - 21s 6ms/step - loss: 0.2802 - val_loss: -0.0108\n",
      "Epoch 3/10\n",
      "3567/3567 [==============================] - 21s 6ms/step - loss: 0.0347 - val_loss: -0.0108\n",
      "Epoch 4/10\n",
      "3567/3567 [==============================] - 21s 6ms/step - loss: 0.0347 - val_loss: -0.0108\n",
      "Epoch 5/10\n",
      "3567/3567 [==============================] - 21s 6ms/step - loss: 0.0347 - val_loss: -0.0108\n",
      "Epoch 6/10\n",
      "3567/3567 [==============================] - 21s 6ms/step - loss: 0.0347 - val_loss: -0.0108\n",
      "Epoch 7/10\n",
      "3567/3567 [==============================] - 21s 6ms/step - loss: 0.0347 - val_loss: -0.0108\n",
      "Epoch 8/10\n",
      "3567/3567 [==============================] - 21s 6ms/step - loss: 0.0347 - val_loss: -0.0108\n",
      "Epoch 9/10\n",
      "3567/3567 [==============================] - 21s 6ms/step - loss: 0.0347 - val_loss: -0.0108\n",
      "Epoch 10/10\n",
      "3567/3567 [==============================] - 21s 6ms/step - loss: 0.0347 - val_loss: -0.0108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f804c2771d0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train, nb_epoch = 10, batch_size = 32, shuffle = False, validation_data = (X_test, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f6dd888a05832e3c4e33f0f332a63627b978e66f"
   },
   "source": [
    "## Use Encoder level to reduce dimension of train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "_uuid": "860f008c14de651c65b10c6665cb9a0609625754"
   },
   "outputs": [],
   "source": [
    "encoder = Model(inputs = input_dim, outputs = encoded13)\n",
    "encoded_input = Input(shape = (encoding_dim, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cce6bab9aa6d1ac22f2f21f43c95bec0d77650ca"
   },
   "source": [
    "### Predict the new train and test data using Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "_uuid": "cdcc8f55565636f7b1d4a36129ffe736ae206073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3567, 200)\n"
     ]
    }
   ],
   "source": [
    "encoded_train = pd.DataFrame(encoder.predict(X_train))\n",
    "encoded_train = encoded_train.add_prefix('feature_')\n",
    "\n",
    "encoded_test = pd.DataFrame(encoder.predict(X_test))\n",
    "encoded_test = encoded_test.add_prefix('feature_')\n",
    "print(encoded_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eaaf050d32c810c5aa49ba39bffa60855a2c73bd"
   },
   "source": [
    "### Add target to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "_uuid": "47ee18e322ed028ff1f3b455d75a1dc5d856e87d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3567, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_28</th>\n",
       "      <th>feature_29</th>\n",
       "      <th>feature_30</th>\n",
       "      <th>feature_31</th>\n",
       "      <th>feature_32</th>\n",
       "      <th>feature_33</th>\n",
       "      <th>feature_34</th>\n",
       "      <th>feature_35</th>\n",
       "      <th>feature_36</th>\n",
       "      <th>feature_37</th>\n",
       "      <th>feature_38</th>\n",
       "      <th>feature_39</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_160</th>\n",
       "      <th>feature_161</th>\n",
       "      <th>feature_162</th>\n",
       "      <th>feature_163</th>\n",
       "      <th>feature_164</th>\n",
       "      <th>feature_165</th>\n",
       "      <th>feature_166</th>\n",
       "      <th>feature_167</th>\n",
       "      <th>feature_168</th>\n",
       "      <th>feature_169</th>\n",
       "      <th>feature_170</th>\n",
       "      <th>feature_171</th>\n",
       "      <th>feature_172</th>\n",
       "      <th>feature_173</th>\n",
       "      <th>feature_174</th>\n",
       "      <th>feature_175</th>\n",
       "      <th>feature_176</th>\n",
       "      <th>feature_177</th>\n",
       "      <th>feature_178</th>\n",
       "      <th>feature_179</th>\n",
       "      <th>feature_180</th>\n",
       "      <th>feature_181</th>\n",
       "      <th>feature_182</th>\n",
       "      <th>feature_183</th>\n",
       "      <th>feature_184</th>\n",
       "      <th>feature_185</th>\n",
       "      <th>feature_186</th>\n",
       "      <th>feature_187</th>\n",
       "      <th>feature_188</th>\n",
       "      <th>feature_189</th>\n",
       "      <th>feature_190</th>\n",
       "      <th>feature_191</th>\n",
       "      <th>feature_192</th>\n",
       "      <th>feature_193</th>\n",
       "      <th>feature_194</th>\n",
       "      <th>feature_195</th>\n",
       "      <th>feature_196</th>\n",
       "      <th>feature_197</th>\n",
       "      <th>feature_198</th>\n",
       "      <th>feature_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017052</td>\n",
       "      <td>0.018841</td>\n",
       "      <td>0.232446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205490</td>\n",
       "      <td>0.234781</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>0.075976</td>\n",
       "      <td>0.039910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141624</td>\n",
       "      <td>0.023897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.228913</td>\n",
       "      <td>0.377456</td>\n",
       "      <td>0.423197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458889</td>\n",
       "      <td>0.221314</td>\n",
       "      <td>0.361501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184156</td>\n",
       "      <td>0.031819</td>\n",
       "      <td>0.024069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116762</td>\n",
       "      <td>0.038952</td>\n",
       "      <td>0.008511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072858</td>\n",
       "      <td>0.182320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140987</td>\n",
       "      <td>0.112765</td>\n",
       "      <td>0.263226</td>\n",
       "      <td>0.126650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.349452</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.279717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048724</td>\n",
       "      <td>0.139920</td>\n",
       "      <td>0.184539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235080</td>\n",
       "      <td>0.192422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034645</td>\n",
       "      <td>0.187708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.463136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206183</td>\n",
       "      <td>0.246051</td>\n",
       "      <td>0.021265</td>\n",
       "      <td>0.091818</td>\n",
       "      <td>0.028960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140563</td>\n",
       "      <td>0.037218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216424</td>\n",
       "      <td>0.380657</td>\n",
       "      <td>0.360636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459238</td>\n",
       "      <td>0.221413</td>\n",
       "      <td>0.348406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155276</td>\n",
       "      <td>0.017993</td>\n",
       "      <td>0.029628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104437</td>\n",
       "      <td>0.058736</td>\n",
       "      <td>0.007171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102398</td>\n",
       "      <td>0.190183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157395</td>\n",
       "      <td>0.115674</td>\n",
       "      <td>0.211675</td>\n",
       "      <td>0.143621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034278</td>\n",
       "      <td>0.350346</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034634</td>\n",
       "      <td>0.147944</td>\n",
       "      <td>0.178699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230613</td>\n",
       "      <td>0.172049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019290</td>\n",
       "      <td>0.152296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.061909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.014540</td>\n",
       "      <td>0.173995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.378132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.162557</td>\n",
       "      <td>0.215922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081738</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133856</td>\n",
       "      <td>0.023795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198165</td>\n",
       "      <td>0.312747</td>\n",
       "      <td>0.291193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342151</td>\n",
       "      <td>0.194243</td>\n",
       "      <td>0.281381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125375</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071650</td>\n",
       "      <td>0.029055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112964</td>\n",
       "      <td>0.136784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131730</td>\n",
       "      <td>0.112912</td>\n",
       "      <td>0.193949</td>\n",
       "      <td>0.112210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022306</td>\n",
       "      <td>0.315413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038570</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.127033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198251</td>\n",
       "      <td>0.128447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042227</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.038195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010548</td>\n",
       "      <td>0.016735</td>\n",
       "      <td>0.176047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.382934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163144</td>\n",
       "      <td>0.218678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082175</td>\n",
       "      <td>0.004927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135143</td>\n",
       "      <td>0.022442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196204</td>\n",
       "      <td>0.314395</td>\n",
       "      <td>0.293159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342726</td>\n",
       "      <td>0.192705</td>\n",
       "      <td>0.283679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068373</td>\n",
       "      <td>0.030982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115510</td>\n",
       "      <td>0.136903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128364</td>\n",
       "      <td>0.114357</td>\n",
       "      <td>0.197681</td>\n",
       "      <td>0.112272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022486</td>\n",
       "      <td>0.312450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.228746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039018</td>\n",
       "      <td>0.161871</td>\n",
       "      <td>0.129240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199019</td>\n",
       "      <td>0.130022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040671</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.038301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009598</td>\n",
       "      <td>0.014198</td>\n",
       "      <td>0.177473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165165</td>\n",
       "      <td>0.216420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081659</td>\n",
       "      <td>0.004280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138681</td>\n",
       "      <td>0.022156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198431</td>\n",
       "      <td>0.320732</td>\n",
       "      <td>0.295069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.347333</td>\n",
       "      <td>0.193977</td>\n",
       "      <td>0.286144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126446</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069819</td>\n",
       "      <td>0.033211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117019</td>\n",
       "      <td>0.139514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132273</td>\n",
       "      <td>0.115830</td>\n",
       "      <td>0.195431</td>\n",
       "      <td>0.110913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022959</td>\n",
       "      <td>0.317249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038068</td>\n",
       "      <td>0.161165</td>\n",
       "      <td>0.132752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200478</td>\n",
       "      <td>0.130338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.042989</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.033819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1     ...       feature_198  feature_199\n",
       "0   0.017052   0.018841     ...          0.000000     0.024058\n",
       "1   0.018911   0.000000     ...          0.000000     0.041199\n",
       "2   0.010171   0.014540     ...          0.001417     0.038195\n",
       "3   0.010548   0.016735     ...          0.002793     0.038301\n",
       "4   0.009598   0.014198     ...          0.002920     0.033819\n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(encoded_train.shape)\n",
    "encoded_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "_uuid": "db0d9e0a47235655f6461e16650e1a9350f37d11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(892, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_28</th>\n",
       "      <th>feature_29</th>\n",
       "      <th>feature_30</th>\n",
       "      <th>feature_31</th>\n",
       "      <th>feature_32</th>\n",
       "      <th>feature_33</th>\n",
       "      <th>feature_34</th>\n",
       "      <th>feature_35</th>\n",
       "      <th>feature_36</th>\n",
       "      <th>feature_37</th>\n",
       "      <th>feature_38</th>\n",
       "      <th>feature_39</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_160</th>\n",
       "      <th>feature_161</th>\n",
       "      <th>feature_162</th>\n",
       "      <th>feature_163</th>\n",
       "      <th>feature_164</th>\n",
       "      <th>feature_165</th>\n",
       "      <th>feature_166</th>\n",
       "      <th>feature_167</th>\n",
       "      <th>feature_168</th>\n",
       "      <th>feature_169</th>\n",
       "      <th>feature_170</th>\n",
       "      <th>feature_171</th>\n",
       "      <th>feature_172</th>\n",
       "      <th>feature_173</th>\n",
       "      <th>feature_174</th>\n",
       "      <th>feature_175</th>\n",
       "      <th>feature_176</th>\n",
       "      <th>feature_177</th>\n",
       "      <th>feature_178</th>\n",
       "      <th>feature_179</th>\n",
       "      <th>feature_180</th>\n",
       "      <th>feature_181</th>\n",
       "      <th>feature_182</th>\n",
       "      <th>feature_183</th>\n",
       "      <th>feature_184</th>\n",
       "      <th>feature_185</th>\n",
       "      <th>feature_186</th>\n",
       "      <th>feature_187</th>\n",
       "      <th>feature_188</th>\n",
       "      <th>feature_189</th>\n",
       "      <th>feature_190</th>\n",
       "      <th>feature_191</th>\n",
       "      <th>feature_192</th>\n",
       "      <th>feature_193</th>\n",
       "      <th>feature_194</th>\n",
       "      <th>feature_195</th>\n",
       "      <th>feature_196</th>\n",
       "      <th>feature_197</th>\n",
       "      <th>feature_198</th>\n",
       "      <th>feature_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014790</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>0.181817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168645</td>\n",
       "      <td>0.223106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083983</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138308</td>\n",
       "      <td>0.022702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204133</td>\n",
       "      <td>0.326118</td>\n",
       "      <td>0.303089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354712</td>\n",
       "      <td>0.199693</td>\n",
       "      <td>0.293299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127383</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072432</td>\n",
       "      <td>0.036015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119557</td>\n",
       "      <td>0.139582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132208</td>\n",
       "      <td>0.112960</td>\n",
       "      <td>0.194998</td>\n",
       "      <td>0.111458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021536</td>\n",
       "      <td>0.317816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039031</td>\n",
       "      <td>0.162801</td>\n",
       "      <td>0.134751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204779</td>\n",
       "      <td>0.137498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043701</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.037077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>0.263050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203782</td>\n",
       "      <td>0.267159</td>\n",
       "      <td>0.040044</td>\n",
       "      <td>0.089428</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143603</td>\n",
       "      <td>0.015549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222370</td>\n",
       "      <td>0.393945</td>\n",
       "      <td>0.384028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510144</td>\n",
       "      <td>0.242582</td>\n",
       "      <td>0.392251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187145</td>\n",
       "      <td>0.037637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126433</td>\n",
       "      <td>0.062808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104227</td>\n",
       "      <td>0.222230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.162427</td>\n",
       "      <td>0.140386</td>\n",
       "      <td>0.258662</td>\n",
       "      <td>0.164976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021393</td>\n",
       "      <td>0.378084</td>\n",
       "      <td>0.029601</td>\n",
       "      <td>0.295033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073687</td>\n",
       "      <td>0.178084</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218321</td>\n",
       "      <td>0.213319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034016</td>\n",
       "      <td>0.153881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009626</td>\n",
       "      <td>0.014807</td>\n",
       "      <td>0.195583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.442496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190936</td>\n",
       "      <td>0.240343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091232</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148691</td>\n",
       "      <td>0.013997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226727</td>\n",
       "      <td>0.364907</td>\n",
       "      <td>0.351550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.414619</td>\n",
       "      <td>0.236660</td>\n",
       "      <td>0.332211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153862</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088005</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128602</td>\n",
       "      <td>0.152657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158771</td>\n",
       "      <td>0.119465</td>\n",
       "      <td>0.214661</td>\n",
       "      <td>0.122727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025544</td>\n",
       "      <td>0.357708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044111</td>\n",
       "      <td>0.171803</td>\n",
       "      <td>0.144601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233117</td>\n",
       "      <td>0.162349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009847</td>\n",
       "      <td>0.016581</td>\n",
       "      <td>0.178357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168749</td>\n",
       "      <td>0.221920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082565</td>\n",
       "      <td>0.005629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141442</td>\n",
       "      <td>0.020743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203583</td>\n",
       "      <td>0.323655</td>\n",
       "      <td>0.301796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353834</td>\n",
       "      <td>0.197666</td>\n",
       "      <td>0.290664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129005</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072406</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119216</td>\n",
       "      <td>0.141585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133172</td>\n",
       "      <td>0.116311</td>\n",
       "      <td>0.199148</td>\n",
       "      <td>0.113160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023428</td>\n",
       "      <td>0.319799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038329</td>\n",
       "      <td>0.163219</td>\n",
       "      <td>0.132914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204821</td>\n",
       "      <td>0.132291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044208</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.035763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.016017</td>\n",
       "      <td>0.179825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169582</td>\n",
       "      <td>0.223436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082595</td>\n",
       "      <td>0.005816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143732</td>\n",
       "      <td>0.021721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204212</td>\n",
       "      <td>0.325635</td>\n",
       "      <td>0.304628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355513</td>\n",
       "      <td>0.199092</td>\n",
       "      <td>0.292463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130009</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073056</td>\n",
       "      <td>0.034570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120467</td>\n",
       "      <td>0.142612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133336</td>\n",
       "      <td>0.116802</td>\n",
       "      <td>0.200117</td>\n",
       "      <td>0.114479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023120</td>\n",
       "      <td>0.320147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038886</td>\n",
       "      <td>0.164753</td>\n",
       "      <td>0.134407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206109</td>\n",
       "      <td>0.133620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045435</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.037066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1     ...       feature_198  feature_199\n",
       "0   0.014790   0.011876     ...          0.000577     0.037077\n",
       "1   0.000000   0.004320     ...          0.000000     0.026152\n",
       "2   0.009626   0.014807     ...          0.000000     0.043508\n",
       "3   0.009847   0.016581     ...          0.000852     0.035763\n",
       "4   0.011004   0.016017     ...          0.000041     0.037066\n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(encoded_test.shape)\n",
    "encoded_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "_uuid": "8eb8bed8d7b992e0e66b2fa57e3a6ddfe5f8a4b7"
   },
   "outputs": [],
   "source": [
    "encoded_train.to_csv('train_encoded.csv', index=False)\n",
    "encoded_test.to_csv('test_encoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "_uuid": "259f5bcbd4b32ca5960f828b7b65a4c6edab16f2"
   },
   "outputs": [],
   "source": [
    "encoded_test = encoded_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "_uuid": "a0afd9bcb5e238e73a20aaee65942406a7602442"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8049c31240>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(encoded_train.isnull(),yticklabels = False,cbar = False,cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "_uuid": "3cbd622b706c210df8173608eb1731b1aed22e2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "missing_val_count_by_column = (encoded_test.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bebb1f0fd4a13fd0c45e65a8f3158babffc2a01d"
   },
   "outputs": [],
   "source": [
    "#encoder + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "_uuid": "6407704e8f1cedb1e2604d0cfe314bcdefca16c4"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=None)\n",
    "x_train = pca.fit_transform(encoded_train)\n",
    "x_test = pca.transform(encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "_uuid": "77996d59badb604abe171f593f8cc3193c7dcf7b"
   },
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "_uuid": "3d6f5b1a1b08fcf8d8264ca2ce3c4086023991ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.97473604e-01, 2.28919843e-02, 4.98794875e-03, 4.69555576e-03,\n",
       "       4.23348429e-03, 3.68658014e-03, 3.42102965e-03, 3.24942381e-03,\n",
       "       3.03642646e-03, 2.67495772e-03, 2.60997540e-03, 2.48250535e-03,\n",
       "       2.25411615e-03, 2.08806940e-03, 1.87029800e-03, 1.85866663e-03,\n",
       "       1.74378075e-03, 1.68813810e-03, 1.61853364e-03, 1.57225220e-03,\n",
       "       1.51810742e-03, 1.31366891e-03, 1.23943480e-03, 1.17016032e-03,\n",
       "       1.13433902e-03, 1.10993052e-03, 1.03575827e-03, 9.83813132e-04,\n",
       "       9.52596881e-04, 9.12104748e-04, 8.71536401e-04, 8.14067449e-04,\n",
       "       7.52020069e-04, 7.22843244e-04, 7.08292682e-04, 7.07290497e-04,\n",
       "       6.88218031e-04, 6.50108635e-04, 6.15660919e-04, 5.80930795e-04,\n",
       "       5.18668619e-04, 4.94803641e-04, 4.87798182e-04, 4.55109649e-04,\n",
       "       4.39102564e-04, 4.24111997e-04, 3.98657719e-04, 3.77176515e-04,\n",
       "       3.60552871e-04, 3.51806812e-04, 3.43929663e-04, 3.29616932e-04,\n",
       "       3.19127987e-04, 2.93495596e-04, 2.87856775e-04, 2.61497828e-04,\n",
       "       2.51825976e-04, 2.46800766e-04, 2.33303515e-04, 2.24407470e-04,\n",
       "       2.02079149e-04, 1.98815636e-04, 1.87717038e-04, 1.75887799e-04,\n",
       "       1.66333815e-04, 1.63083252e-04, 1.59199883e-04, 1.52152138e-04,\n",
       "       1.48593551e-04, 1.40019018e-04, 1.34074178e-04, 1.28503330e-04,\n",
       "       1.19863144e-04, 1.18277609e-04, 1.14984858e-04, 1.09840843e-04,\n",
       "       1.05725016e-04, 9.95479413e-05, 9.63208194e-05, 9.10693040e-05,\n",
       "       8.67165999e-05, 8.14628691e-05, 7.90147330e-05, 7.47617221e-05,\n",
       "       6.75833418e-05, 6.55176443e-05, 6.28128938e-05, 6.20381917e-05,\n",
       "       5.93161359e-05, 5.85408357e-05, 5.18455228e-05, 5.01562005e-05,\n",
       "       4.89829117e-05, 4.72356922e-05, 4.63797106e-05, 4.37449340e-05,\n",
       "       4.11768940e-05, 3.89639133e-05, 3.83190843e-05, 3.36783627e-05,\n",
       "       3.18915466e-05, 3.13984442e-05, 2.82789063e-05, 2.65114860e-05,\n",
       "       2.44559097e-05, 2.30239101e-05, 2.14963682e-05, 1.96506424e-05,\n",
       "       1.69736060e-05, 1.56865142e-05, 1.34362418e-05, 1.21209403e-05,\n",
       "       1.14785649e-05, 1.10863405e-05, 1.02922622e-05, 9.61235772e-06,\n",
       "       6.71738443e-06, 6.01107009e-06, 3.49083587e-06, 2.56378988e-06,\n",
       "       2.37216443e-06, 2.09354899e-06, 4.73983995e-07, 3.21708850e-07,\n",
       "       1.31444766e-07, 8.18292393e-08, 5.54685029e-08, 4.30035185e-08,\n",
       "       2.66508273e-08, 2.24115117e-08, 1.62327108e-10, 1.76995460e-31,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33,\n",
       "       6.89022788e-33, 6.89022788e-33, 6.89022788e-33, 6.89022788e-33])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "_uuid": "72d91fbc006f669103a9974d6c061c502e2b86a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9184666846350971\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBRegressor(n_estimators=35, learning_rate=0.06, gamma=0, subsample=0.6,\n",
    "                           colsample_bytree=0.7, min_child_weight=4, max_depth=3)\n",
    "                           \n",
    "                           \n",
    "xgb.fit(x_train,y_train)\n",
    "predictions = xgb.predict(x_test)\n",
    "print(metrics.mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "_uuid": "ef36116a8c5dbc0cfb4eb32c96d89d4c9f957471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0088379732492547\n"
     ]
    }
   ],
   "source": [
    "rand = RandomForestRegressor(n_estimators = 10,random_state = 0)\n",
    "rand.fit(x_train,y_train)\n",
    "y_pred2 = rand.predict(x_test)\n",
    "print(metrics.mean_squared_error(y_test,y_pred2 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "_uuid": "6bbac2289e03d440936a6c8d853f9b1efb46aa72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8860584752682324e+23\n"
     ]
    }
   ],
   "source": [
    "logreg=LinearRegression()\n",
    "logreg.fit(x_train,y_train)\n",
    "y_pred=logreg.predict(x_test)\n",
    "\n",
    "y_pred\n",
    "print(metrics.mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "_uuid": "a000e624a6a8d3e6f6f56ceacbac964277ac631f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.3416815129317925\n"
     ]
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor( random_state = 0)\n",
    "regressor.fit(x_train,y_train)\n",
    "y_pred1 = regressor.predict(x_test)\n",
    "print(metrics.mean_squared_error(y_test,y_pred1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "_uuid": "0bff009a2a6abec9187113626fb347f862898b6c"
   },
   "outputs": [],
   "source": [
    "scale_list = train2.columns[1:]\n",
    "sc = train2[scale_list]\n",
    "scaler = StandardScaler()\n",
    "sc = scaler.fit_transform(sc)\n",
    "train2[scale_list] = sc\n",
    "train2[scale_list].head()\n",
    "\n",
    "X = train2.drop(['target','ID'], axis=1)\n",
    "Y = train2['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y ,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f3a82fef62b9baaec90162dd7ceb725f4bb4e08"
   },
   "outputs": [],
   "source": [
    "#PCA ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "_uuid": "2acd8f7421112fae4abc2096b375c795d2319173"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=None)\n",
    "x2_train = pca.fit_transform(X_train)\n",
    "x2_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "_uuid": "2b32c41335cf122b8b6fd5c02746ec7818ac3af2"
   },
   "outputs": [],
   "source": [
    "explained_variance2 = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "_uuid": "a84d0f2e61b8423adcb0a9c164165f504aeb0eab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.3416815129317925\n"
     ]
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor( random_state = 0)\n",
    "regressor.fit(x2_train,y_train)\n",
    "y_pred1 = regressor.predict(x2_test)\n",
    "print(metrics.mean_squared_error(y_test,y_pred1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "_uuid": "2dedb272e0e1a23f4ed768b3da8faeaaac5d0bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9184666846350971\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBRegressor(n_estimators=35, learning_rate=0.06, gamma=0, subsample=0.6,\n",
    "                           colsample_bytree=0.7, min_child_weight=4, max_depth=3)\n",
    "                           \n",
    "                           \n",
    "xgb.fit(x2_train,y_train)\n",
    "predictions = xgb.predict(x2_test)\n",
    "print(metrics.mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "_uuid": "1d02b32b5042f3a03b55d80d413538e672abb7db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0088379732492547\n"
     ]
    }
   ],
   "source": [
    "rand = RandomForestRegressor(n_estimators = 10,random_state = 0)\n",
    "rand.fit(x2_train,y_train)\n",
    "y_pred2 = rand.predict(x2_test)\n",
    "print(metrics.mean_squared_error(y_test,y_pred2 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "_uuid": "b20ad009035e80c3109a97c973e4206150f5ed3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8860584752682324e+23\n"
     ]
    }
   ],
   "source": [
    "logreg=LinearRegression()\n",
    "logreg.fit(x2_train,y_train)\n",
    "y_pred=logreg.predict(x2_test)\n",
    "\n",
    "y_pred\n",
    "print(metrics.mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "_uuid": "76044d6daf6c8393212d8dce69be3eff6203183e"
   },
   "outputs": [],
   "source": [
    "#KERNEL PCA + ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "_uuid": "0f6bf9cfef30deae13ac5c6775aeefbdaa548767"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import  KernelPCA\n",
    "kpca = KernelPCA(n_components = 2, kernel = 'rbf')\n",
    "x4_train = kpca.fit_transform(encoded_train)\n",
    "x4_test = kpca.transform(encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "_uuid": "55babc3a84866a14b6d981eb322313015d667442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1897963692832154\n"
     ]
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor( random_state = 0)\n",
    "regressor.fit(x4_train,y_train)\n",
    "y_pred1 = regressor.predict(x4_test)\n",
    "print(metrics.mean_squared_error(y_test,y_pred1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "_uuid": "aab81979c2ddfe2d8b65b1664c35d06a846f97f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0717463743702915\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBRegressor(n_estimators=35, learning_rate=0.06, gamma=0, subsample=0.6,\n",
    "                           colsample_bytree=0.7, min_child_weight=4, max_depth=3)\n",
    "                           \n",
    "                           \n",
    "xgb.fit(x4_train,y_train)\n",
    "predictions = xgb.predict(x4_test)\n",
    "print(metrics.mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "_uuid": "ac3f6b3cd75d4e6b20419a40e3f9360719c05d3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0088379732492547\n"
     ]
    }
   ],
   "source": [
    "rand = RandomForestRegressor(n_estimators = 10,random_state = 0)\n",
    "rand.fit(x4_train,y_train)\n",
    "y_pred2 = rand.predict(x4_test)\n",
    "print(metrics.mean_squared_error(y_test,y_pred2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "_uuid": "e0617e1f372c2b6616dea8043275d3f916071de7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.071997067379852\n"
     ]
    }
   ],
   "source": [
    "logreg=LinearRegression()\n",
    "logreg.fit(x4_train,y_train)\n",
    "y_pred=logreg.predict(x4_test)\n",
    "\n",
    "y_pred\n",
    "print(metrics.mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eca2f573b7a83e1b03436e60d9ab5bd82502572c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "10c9c77c4a634197361f2630af59d2d810e8a959"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
